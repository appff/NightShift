#!/usr/bin/env python3
"""
Night Shift: Autonomous AI Agent Wrapper (v3.0 - Stateless CLI Wrapper)
Target: macOS M3 (Apple Silicon)
Version: 3.0.0

Core Features:
1. Brain Module (LLM) for autonomous decision making.
2. OODA Loop (Observe-Orient-Decide-Act) architecture.
3. Multi-LLM Support (Gemini, Claude, GPT).
4. Robust communication with Claude Code using non-interactive mode (`claude -p`).
"""

import subprocess
import sys
import time
import yaml
import re
import os
import argparse
from datetime import datetime
import json # For parsing Claude's JSON output if applicable

# --- Third-party LLM SDKs ---
from google import genai
from openai import OpenAI
from anthropic import Anthropic

# --- Configuration & Constants ---

# ANSI Escape Code Regex for cleaning output before analysis
ANSI_ESCAPE_PATTERN = re.compile(r'\x1B(?:[@-Z\-_]|[0-?]*[@-~])')

# File paths
LOG_DIR = "logs"
LOG_FILE_TEMPLATE = os.path.join(LOG_DIR, "night_shift_log_{timestamp}.txt")
REPORT_FILE = "morning_report.md"
SETTINGS_FILE = "settings.yaml"

# LLM Configuration
# ê°€ë…ì„± ê°œì„ : ë§¤ì§ ë„˜ë²„ë¥¼ ëª…í™•í•œ ì´ë¦„ì˜ ìƒìˆ˜ë¡œ ì¶”ì¶œí•˜ì—¬ ì˜ë„ë¥¼ ëª…í™•íˆ í•¨
MAX_CONTEXT_CHARS = 3000  # Brainì— ì „ë‹¬í•  Claude ì¶œë ¥ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜
MAX_HISTORY_CHARS = 4000  # Brainì— ì „ë‹¬í•  ëŒ€í™” íˆìŠ¤í† ë¦¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜
MAX_TOKENS = 1024  # LLM ì‘ë‹µì˜ ìµœëŒ€ í† í° ìˆ˜
RATE_LIMIT_SLEEP = 2  # Brain ë°˜ë³µ ì‚¬ì´ì˜ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)

# Default model names
# ìœ ì§€ë³´ìˆ˜ì„± ê°œì„ : ëª¨ë¸ëª…ì„ í•œ ê³³ì—ì„œ ê´€ë¦¬í•˜ì—¬ ë³€ê²½ ì‹œ ìˆ˜ì • ì§€ì ì„ ëª…í™•íˆ í•¨
DEFAULT_GEMINI_MODEL = 'gemini-1.5-pro'
DEFAULT_GPT_MODEL = 'gpt-4o'
DEFAULT_CLAUDE_MODEL = 'claude-3-opus-20240229'


# --- Schema Validation Functions ---

def validate_settings_schema(settings):
    """
    settings.yamlì˜ ìŠ¤í‚¤ë§ˆë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
    
    Args:
        settings: ê²€ì¦í•  ì„¤ì • ë”•ì…”ë„ˆë¦¬
        
    Raises:
        ValueError: ìŠ¤í‚¤ë§ˆê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
    """
    if not isinstance(settings, dict):
        raise ValueError("Settings must be a dictionary")
    
    brain_config = settings.get('brain', {})
    if not isinstance(brain_config, dict):
        raise ValueError("'brain' configuration must be a dictionary")
    
    active_model = brain_config.get('active_model', '')
    valid_models = ['gemini', 'gpt', 'claude']
    if active_model and active_model not in valid_models:
        raise ValueError(f"active_model must be one of {valid_models}, got: {active_model}")
    
    # ê° ëª¨ë¸ ì„¤ì • ê²€ì¦
    for model_name in valid_models:
        if model_name in brain_config:
            model_config = brain_config[model_name]
            if not isinstance(model_config, dict):
                raise ValueError(f"'{model_name}' configuration must be a dictionary")

def validate_mission_schema(mission_config):
    """
    mission.yamlì˜ ìŠ¤í‚¤ë§ˆë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
    
    Args:
        mission_config: ê²€ì¦í•  ë¯¸ì…˜ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        
    Raises:
        ValueError: ìŠ¤í‚¤ë§ˆê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
    """
    if not isinstance(mission_config, dict):
        raise ValueError("Mission configuration must be a dictionary")
    
    # í•„ìˆ˜ í•„ë“œ ê²€ì¦
    if 'mission_name' not in mission_config:
        raise ValueError("Missing required field: 'mission_name'")
    
    if 'goal' not in mission_config or not mission_config['goal']:
        raise ValueError("Missing or empty required field: 'goal'")
    
    # ì„ íƒ í•„ë“œ íƒ€ì… ê²€ì¦
    if 'project_path' in mission_config and not isinstance(mission_config['project_path'], str):
        raise ValueError("'project_path' must be a string")
    
    if 'constraints' in mission_config and not isinstance(mission_config['constraints'], list):
        raise ValueError("'constraints' must be a list")

class Brain:
    """The Intelligence Unit. Decides what to do based on the mission and current context."""
    
    def __init__(self, settings_path=SETTINGS_FILE):
        self.settings = self._load_settings(settings_path)
        self.model_type = self.settings.get('brain', {}).get('active_model', 'gemini')
        self.client = None
        self.model_name = ""
        self._setup_client()
        
        print(f"ğŸ§  Brain Initialized: [{self.model_type.upper()}] Mode with model: {self.model_name}")

    def _load_settings(self, path):
        """
        ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•˜ê³  ìŠ¤í‚¤ë§ˆë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
        
        Args:
            path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
            
        Returns:
            dict: íŒŒì‹±ë˜ê³  ê²€ì¦ëœ ì„¤ì • ë”•ì…”ë„ˆë¦¬ (íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬)
            
        Raises:
            ValueError: ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨ ì‹œ
        """
        if not os.path.exists(path):
            print(f"âš ï¸  Settings file not found: {path}. Using defaults.")
            return {}
        
        with open(path, 'r', encoding='utf-8') as file:
            settings = yaml.safe_load(file)
        
        # ìŠ¤í‚¤ë§ˆ ê²€ì¦
        try:
            validate_settings_schema(settings)
        except ValueError as e:
            print(f"âŒ Settings validation error: {e}")
            raise
        
        return settings

    def _setup_client(self):
        """
        LLM í´ë¼ì´ì–¸íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        
        Raises:
            ValueError: API í‚¤ê°€ ì—†ê±°ë‚˜ ì˜ëª»ëœ ëª¨ë¸ íƒ€ì…ì¸ ê²½ìš°
        """
        brain_config = self.settings.get('brain', {})

        if self.model_type == 'gemini':
            config = brain_config.get('gemini', {})
            api_key = config.get('api_key') or os.getenv("GEMINI_API_KEY")
            if not api_key:
                raise ValueError("Gemini API Key is missing in settings.yaml or env vars.")
            self.client = genai.Client(api_key=api_key)
            self.model_name = config.get('model', DEFAULT_GEMINI_MODEL)

        elif self.model_type == 'gpt':
            config = brain_config.get('gpt', {})
            api_key = config.get('api_key') or os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OpenAI API Key is missing in settings.yaml or env vars.")
            self.client = OpenAI(api_key=api_key)
            self.model_name = config.get('model', DEFAULT_GPT_MODEL)

        elif self.model_type == 'claude':
            config = brain_config.get('claude', {})
            api_key = config.get('api_key') or os.getenv("CLAUDE_API_KEY")
            if not api_key:
                raise ValueError("Anthropic API Key is missing in settings.yaml or env vars.")
            self.client = Anthropic(api_key=api_key)
            self.model_name = config.get('model', DEFAULT_CLAUDE_MODEL)
        
        else:
            raise ValueError(f"Unsupported model type: '{self.model_type}'. Choose from: gemini, gpt, claude.")

    def clean_ansi(self, text):
        return ANSI_ESCAPE_PATTERN.sub('', text)

    def _build_director_prompt(self, mission_goal, constraints, conversation_history, clean_output):
        """
        Director í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
        
        Args:
            mission_goal: ë¯¸ì…˜ ëª©í‘œ
            constraints: ì œì•½ì‚¬í•­ ë¦¬ìŠ¤íŠ¸
            conversation_history: ëŒ€í™” ì´ë ¥
            clean_output: ANSI ì½”ë“œê°€ ì œê±°ëœ Claude ì¶œë ¥
            
        Returns:
            str: êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸
        """
        constraints_text = '\n'.join(constraints) if isinstance(constraints, list) else str(constraints)
        
        prompt = f"""
You are the "Director" of an autonomous coding session.
Your "Actor" is a non-interactive CLI tool (Claude Code) which you invoke with `claude -p "YOUR_COMMAND_HERE" -c`.
Your goal is to guide the Actor to achieve the [MISSION GOAL].

[MISSION GOAL]
{mission_goal}

[CONSTRAINTS]
{constraints_text}

[CONVERSATION HISTORY]
{conversation_history[-MAX_HISTORY_CHARS:]}

[LAST ACTOR'S OUTPUT]
{clean_output}

[INSTRUCTIONS]
1. Analyze the [MISSION GOAL], [CONSTRAINTS], [CONVERSATION HISTORY], and [LAST ACTOR'S OUTPUT].
2. Determine the NEXT single, specific, and actionable command/query to send to Claude Code via the `-p` flag to move closer to the [MISSION GOAL].
3. **Handle Actor's Prompts:**
   - If the Actor proposes a plan, evaluate it against the [MISSION GOAL]. If good, reply with "Proceed" or "Yes".
   - If the Actor offers choices (e.g., "English or Korean?"), select the one that best fits the goal/constraints.
   - If the Actor needs confirmation (e.g., "y/n"), provide it.
4. If the Actor's output indicates the mission is complete, or you believe no further action is needed, reply with exactly: "MISSION_COMPLETED".
5. The command you output will be executed as `claude -p "YOUR_OUTPUT_HERE" -c`. Ensure it's a valid query for Claude Code.

[CRITICAL RULE]
- Your response MUST be ONLY the command/query string. No markdown, no explanations, no wrapping in quotes unless the command itself requires it.
- Do NOT repeat the exact same command if it was just executed and yielded no progress.
- Be concise and direct.
"""
        return prompt

    def _call_llm_api(self, prompt):
        """
        ì„¤ì •ëœ LLM APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.
        
        Args:
            prompt: LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸
            
        Returns:
            str: LLMì˜ ì‘ë‹µ í…ìŠ¤íŠ¸
            
        Raises:
            ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…ì¸ ê²½ìš°
            RuntimeError: LLM API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        try:
            if self.model_type == 'gemini':
                # ê°€ë…ì„± ê°œì„ : ë³€ìˆ˜ëª…ì„ ëª…í™•í•˜ê²Œ ë³€ê²½ (resp â†’ response)
                response = self.client.models.generate_content(
                    model=self.model_name,
                    contents=prompt
                )
                response_text = response.text.strip()
                print(f"--- ğŸ§  BRAIN RAW RESPONSE ---\n{response_text}\n--- END RAW RESPONSE ---")
                return response_text

            elif self.model_type == 'gpt':
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": "You are a helpful AI Director. Respond ONLY with the command to execute."},
                        {"role": "user", "content": prompt}
                    ]
                )
                response_text = response.choices[0].message.content.strip()
                print(f"--- ğŸ§  BRAIN RAW RESPONSE ---\n{response_text}\n--- END RAW RESPONSE ---")
                return response_text

            elif self.model_type == 'claude':
                message = self.client.messages.create(
                    model=self.model_name,
                    max_tokens=MAX_TOKENS,
                    messages=[{"role": "user", "content": prompt}]
                )
                response_text = message.content[0].text.strip()
                print(f"--- ğŸ§  BRAIN RAW RESPONSE ---\n{response_text}\n--- END RAW RESPONSE ---")
                return response_text
            
            else:
                raise ValueError(f"Unknown model type: {self.model_type}")
                
        except ValueError:
            raise
        except Exception as e:
            raise RuntimeError(f"Failed to call {self.model_type} LLM: {str(e)}") from e

    def think(self, mission_goal, constraints, conversation_history, last_claude_output):
        """
        ìƒí™©ì„ ë¶„ì„í•˜ê³  Claude Codeë¥¼ ìœ„í•œ ë‹¤ìŒ ëª…ë ¹ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            mission_goal: ë¯¸ì…˜ ëª©í‘œ
            constraints: ì œì•½ì‚¬í•­ ë¦¬ìŠ¤íŠ¸
            conversation_history: ëŒ€í™” ì´ë ¥
            last_claude_output: ë§ˆì§€ë§‰ Claude ì¶œë ¥
            
        Returns:
            str: ë‹¤ìŒì— ì‹¤í–‰í•  ëª…ë ¹ì–´ ë˜ëŠ” "MISSION_COMPLETED"/"MISSION_FAILED"
        """
        # ANSI ì´ìŠ¤ì¼€ì´í”„ ì½”ë“œ ì œê±° ë° ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ì œí•œ
        clean_output = self.clean_ansi(last_claude_output)[-MAX_CONTEXT_CHARS:]

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._build_director_prompt(mission_goal, constraints, conversation_history, clean_output)
        
        # ë””ë²„ê¹… ë° ë¡œê¹…ìš© í”„ë¡¬í”„íŠ¸ ì¶œë ¥
        print("\n--- ğŸ§  PROMPT TO BRAIN ---")
        print(prompt)
        print("--- END PROMPT ---")
        
        # ë¡œê·¸ íŒŒì¼ì—ë„ ê¸°ë¡ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
        log_entry = f"\n{'='*80}\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] BRAIN REQUEST\n{'='*80}\n{prompt}\n"
        self._log_to_file(log_entry)

        try:
            # LLM API í˜¸ì¶œ
            response_text = self._call_llm_api(prompt)
            
            # ì‘ë‹µë„ ë¡œê·¸ì— ê¸°ë¡
            response_log = f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] BRAIN RESPONSE\n{'-'*80}\n{response_text}\n"
            self._log_to_file(response_log)
            
            return response_text
            
        except ValueError as e:
            # ì„¤ì • ì˜¤ë¥˜ (ì˜ëª»ëœ ëª¨ë¸ íƒ€ì…)
            print(f"ğŸ§  Brain Configuration Error: {e}")
            error_msg = f"MISSION_FAILED: Configuration error - {e}"
            self._log_to_file(f"\nâŒ ERROR: {error_msg}\n")
            return error_msg
            
        except RuntimeError as e:
            # LLM API í˜¸ì¶œ ì‹¤íŒ¨
            print(f"ğŸ§  Brain Freeze (LLM Error): {e}")
            error_msg = f"MISSION_FAILED: {e}"
            self._log_to_file(f"\nâŒ ERROR: {error_msg}\n")
            return error_msg
            
        except Exception as e:
            # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜
            print(f"ğŸ§  Brain Freeze (Unexpected Error): {e}")
            error_msg = "MISSION_FAILED: Unexpected error during LLM call."
            self._log_to_file(f"\nâŒ ERROR: {error_msg} - {e}\n")
            return error_msg

    def _log_to_file(self, message):
        """
        Brain í™œë™ì„ ì „ìš© ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡í•©ë‹ˆë‹¤.
        
        Args:
            message: ê¸°ë¡í•  ë©”ì‹œì§€
        """
        brain_log_file = os.path.join(LOG_DIR, f"brain_log_{datetime.now().strftime('%Y%m%d')}.txt")
        try:
            with open(brain_log_file, "a", encoding="utf-8") as f:
                f.write(message)
        except Exception as e:
            print(f"âš ï¸ Failed to write to brain log: {e}")

class NightShiftAgent:
    """Night Shift ì—ì´ì „íŠ¸ ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(self, mission_path="mission.yaml"):
        """
        NightShiftAgentë¥¼ ì´ˆê¸°í™”í•˜ê³  ë¯¸ì…˜ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Args:
            mission_path: ë¯¸ì…˜ ì„¤ì • íŒŒì¼ ê²½ë¡œ
            
        Raises:
            SystemExit: ë¯¸ì…˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
            ValueError: ë¯¸ì…˜ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨ ì‹œ
        """
        if not os.path.exists(mission_path):
            print(f"âŒ Mission file not found: {mission_path}")
            sys.exit(1)

        with open(mission_path, 'r', encoding='utf-8') as file:
            self.mission_config = yaml.safe_load(file)
        
        # ë¯¸ì…˜ ìŠ¤í‚¤ë§ˆ ê²€ì¦
        try:
            validate_mission_schema(self.mission_config)
        except ValueError as e:
            print(f"âŒ Mission validation error: {e}")
            sys.exit(1)
        
        if not os.path.exists(LOG_DIR):
            os.makedirs(LOG_DIR)
        
        self.log_file_path = LOG_FILE_TEMPLATE.format(
            timestamp=datetime.now().strftime("%Y%m%d_%H%M%S")
        )
        self.brain = Brain()
        self.conversation_history = ""
        self.last_claude_query = ""
        self.last_claude_output = ""

    def _create_system_prompt_file(self):
        """
        ë©€í‹°ë¼ì¸ goal ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„ì‹œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Returns:
            str: ìƒì„±ëœ íŒŒì¼ëª… ë˜ëŠ” None (goalì´ ì—†ëŠ” ê²½ìš°)
        """
        goal = self.mission_config.get('goal', '')
        if not goal:
            return None
        
        filename = ".night_shift_system_prompt.txt"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(goal)
        return filename

    def _cleanup_system_prompt_file(self, filename):
        """
        ì„ì‹œë¡œ ìƒì„±í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤.
        
        Args:
            filename: ì‚­ì œí•  íŒŒì¼ëª… (Noneì¸ ê²½ìš° ë¬´ì‹œ)
        """
        if filename and os.path.exists(filename):
            os.remove(filename)

    def _build_claude_command(self, query):
        """
        Claude Code ì‹¤í–‰ì„ ìœ„í•œ ëª…ë ¹ì–´ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
        
        Args:
            query: Claudeì—ê²Œ ì „ë‹¬í•  ì¿¼ë¦¬
            
        Returns:
            list: subprocess ì‹¤í–‰ì„ ìœ„í•œ ëª…ë ¹ì–´ ë¦¬ìŠ¤íŠ¸
        """
        command = ["claude"]

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë˜ëŠ” ì§ì ‘ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        if self.system_prompt_file:
            command.extend(["--system-prompt-file", self.system_prompt_file])
        elif self.mission_config.get('goal'):
            command.extend(["--system-prompt", self.mission_config['goal']])

        # ì¿¼ë¦¬ ì¶”ê°€
        command.extend(["-p", query])

        # ëŒ€í™” ê³„ì† í”Œë˜ê·¸
        command.append("-c")
        
        # ìë™ íŒŒì¼ ìˆ˜ì • í—ˆìš©
        command.append("--dangerously-skip-permissions")
        command.extend(["--allowedTools", "Write"])

        return command

    def _execute_subprocess(self, command):
        """
        subprocessë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            command: ì‹¤í–‰í•  ëª…ë ¹ì–´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            tuple: (stdout, stderr, returncode)
        """
        try:
            result = subprocess.run(
                command,
                capture_output=True,
                text=True,
                check=False,
                cwd=self.mission_config.get('project_path', os.getcwd())
            )
            return result.stdout.strip(), result.stderr.strip(), result.returncode
            
        except FileNotFoundError:
            error_msg = "ERROR: 'claude' command not found. Is Claude Code CLI installed and in PATH?"
            return error_msg, "", 1
        except Exception as e:
            error_msg = f"ERROR running Claude Code: {e}"
            return error_msg, "", 1

    def _run_claude_command(self, query):
        """
        Claude Codeë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            query: Claudeì—ê²Œ ì „ë‹¬í•  ëª…ë ¹/ì¿¼ë¦¬
            
        Returns:
            str: Claudeì˜ ì¶œë ¥ ë˜ëŠ” ì—ëŸ¬ ë©”ì‹œì§€
        """
        if not query or query.strip() == "":
            return "ERROR: Brain sent an empty query to Claude Code. Assuming mission failure."

        # ëª…ë ¹ì–´ êµ¬ì„±
        command = self._build_claude_command(query)

        # ëª…ë ¹ì–´ ì •ë³´ ì¶œë ¥
        print(f"\n--- ğŸš€ Running Claude Code ---")
        print(f"Full Command: {' '.join(command)}")
        print(f"Query: {query}")
        print("---")

        # ëª…ë ¹ì–´ ì‹¤í–‰
        output, error, returncode = self._execute_subprocess(command)

        # ê²°ê³¼ ì¶œë ¥
        print(f"--- Claude Code Output ---")
        print(output)
        if error:
            print(f"--- Claude Code Error ---")
            print(error)
        print("---")

        # ì—ëŸ¬ ì²˜ë¦¬
        if returncode != 0:
            return f"Claude Code exited with error code {returncode}:\n{output}\n{error}"
        
        return output

    def start(self):
        """
        Night Shift ì—ì´ì „íŠ¸ë¥¼ ì‹œì‘í•˜ê³  OODA Loopë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        ë¯¸ì…˜ì„ ìˆ˜í–‰í•˜ê³  ëŒ€í™” ë¡œê·¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
        """
        print("ğŸŒ™ Night Shift (v3.0) Starting...")
        
        project_path = self.mission_config.get('project_path', os.getcwd())
        goal = self.mission_config.get('goal', 'No goal specified')
        constraints = self.mission_config.get('constraints', [])
        
        # ë©€í‹°ë¼ì¸ goal ì²˜ë¦¬ë¥¼ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ìƒì„±
        self.system_prompt_file = self._create_system_prompt_file()
        
        try:
            # ì´ˆê¸° ë¯¸ì…˜ ì‹œì‘
            initial_query = "Begin the mission. Analyze the current project based on the system prompt."
            claude_output = self._run_claude_command(initial_query)
            self.conversation_history += f"Director initial instruction: {initial_query}\nActor Output:\n{claude_output}\n"
            self.last_claude_query = initial_query
            self.last_claude_output = claude_output

            # OODA Loop ì‹¤í–‰
            while True:
                print("\nğŸ¤” Brain is thinking...")
                next_action = self.brain.think(
                    goal,
                    constraints,
                    self.conversation_history,
                    self.last_claude_output
                )

                print(f"ğŸ’¡ Director (Brain): {next_action}")

                # Brainì˜ ê²°ì •ì„ ëŒ€í™” ì´ë ¥ì— ê¸°ë¡
                self.conversation_history += f"\n--- ğŸ§  DIRECTOR (BRAIN) DECISION ---\n{next_action}\n----------------------------------\n"

                if next_action == "MISSION_COMPLETED":
                    print("ğŸ‰ Mission Accomplished. Exiting.")
                    break
                
                if next_action.startswith("MISSION_FAILED"):
                    print(f"âŒ {next_action}. Exiting.")
                    break

                if next_action == self.last_claude_query:
                    print(f"âš ï¸ Loop detected: Brain suggested '{next_action}' again without new output. Forcing break.")
                    break

                claude_output = self._run_claude_command(next_action)
                
                # Actorì˜ ì¶œë ¥ì„ ëŒ€í™” ì´ë ¥ì— ì¶”ê°€
                self.conversation_history += f"\n--- ğŸ¤– ACTOR (CLAUDE) OUTPUT ---\n{claude_output}\n------------------------------\n"
                self.last_claude_query = next_action
                self.last_claude_output = claude_output
                
                # Rate limiting
                time.sleep(RATE_LIMIT_SLEEP)

        finally:
            self._cleanup_system_prompt_file(self.system_prompt_file)

        print("\nğŸ‘‹ Night Shift Ended.")
        
        # ëŒ€í™” ë¡œê·¸ ì €ì¥
        with open(self.log_file_path, "w", encoding="utf-8") as file:
            file.write(self.conversation_history)
        print(f"ğŸ“ Full conversation log saved to: {self.log_file_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Night Shift: Brain-Powered Agent")
    parser.add_argument("mission_file", nargs="?", default="mission.yaml")
    args = parser.parse_args()
    
    agent = NightShiftAgent(mission_path=args.mission_file)
    agent.start()